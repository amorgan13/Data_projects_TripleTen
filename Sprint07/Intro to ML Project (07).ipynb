{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Decision Tree, Random Forest, and Logistic Regression for classification tasks with telecom data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to develop a machine learning model that accurately predicts which mobile carrier plan a user will choose based on their usage patterns. By analyzing features such as call minutes, number of messages, and internet data consumption, we aim to identify the key factors influencing customer decisions and automate the classification process.\n",
    "\n",
    "To achieve this, we explore several classification algorithms, compare their performance, and select the most reliable model. The results can help telecom companies better understand customer behavior, improve targeted marketing, and optimize plan offerings. Overall, we hope to develop a model with the highest possible accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five rows:\n",
      "   calls  minutes  messages   mb_used  is_ultra\n",
      "0   40.0   311.90      83.0  19915.42         0\n",
      "1   85.0   516.75      56.0  22696.96         0\n",
      "2   77.0   467.66      86.0  21060.45         0\n",
      "3  106.0   745.53      81.0   8437.39         1\n",
      "4   66.0   418.74       1.0  14502.75         0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the first five rows\n",
    "print(\"First five rows:\")\n",
    "print(df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info about the dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show info about the dataset (including data types and missing values)\n",
    "print(\"Info about the dataset:\")\n",
    "print(df.info(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics:\n",
      "             calls      minutes     messages       mb_used     is_ultra\n",
      "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
      "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
      "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
      "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
      "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
      "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
      "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
      "max     244.000000  1632.060000   224.000000  49745.730000     1.000000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show summary statistics for numeric columns\n",
    "print(\"Summary statistics:\")\n",
    "print(df.describe(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "calls       0\n",
      "minutes     0\n",
      "messages    0\n",
      "mb_used     0\n",
      "is_ultra    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in each column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 1928 samples\n",
      "Validation set: 643 samples\n",
      "Test set: 643 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('users_behavior.csv')\n",
    "\n",
    "# First, separate features and target\n",
    "X = df.drop('is_ultra', axis=1)\n",
    "y = df['is_ultra']\n",
    "\n",
    "# Split into train+val and test (80% train+val, 20% test)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Now split train+val into train and validation (75% train, 25% val of train+val = 60% train, 20% val)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val\n",
    ")\n",
    "\n",
    "print(f\"Train set: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_valid.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Optionally, save splits for later use\n",
    "X_train.to_csv('X_train.csv', index=False)\n",
    "X_valid.to_csv('X_valid.csv', index=False)\n",
    "X_test.to_csv('X_test.csv', index=False)\n",
    "y_train.to_csv('y_train.csv', index=False)\n",
    "y_valid.to_csv('y_valid.csv', index=False)\n",
    "y_test.to_csv('y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                model            params  accuracy\n",
      "1        DecisionTree       max_depth=5  0.790047\n",
      "5        RandomForest   n_estimators=50  0.785381\n",
      "6        RandomForest  n_estimators=100  0.782271\n",
      "0        DecisionTree       max_depth=3  0.777605\n",
      "2        DecisionTree       max_depth=7  0.776050\n",
      "4        RandomForest   n_estimators=10  0.772939\n",
      "7  LogisticRegression             C=0.1  0.744946\n",
      "8  LogisticRegression               C=1  0.744946\n",
      "9  LogisticRegression              C=10  0.744946\n",
      "3        DecisionTree    max_depth=None  0.715397\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load train/validation splits\n",
    "X_train = pd.read_csv('X_train.csv')\n",
    "y_train = pd.read_csv('y_train.csv').squeeze()  # squeeze to convert to Series\n",
    "X_valid = pd.read_csv('X_valid.csv')\n",
    "y_valid = pd.read_csv('y_valid.csv').squeeze()\n",
    "\n",
    "results = []\n",
    "\n",
    "# Decision Tree\n",
    "for max_depth in [3, 5, 7, None]:\n",
    "    clf = DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_valid)\n",
    "    acc = accuracy_score(y_valid, preds)\n",
    "    results.append({\n",
    "        'model': 'DecisionTree',\n",
    "        'params': f'max_depth={max_depth}',\n",
    "        'accuracy': acc\n",
    "    })\n",
    "\n",
    "# Random Forest\n",
    "for n_estimators in [10, 50, 100]:\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_valid)\n",
    "    acc = accuracy_score(y_valid, preds)\n",
    "    results.append({\n",
    "        'model': 'RandomForest',\n",
    "        'params': f'n_estimators={n_estimators}',\n",
    "        'accuracy': acc\n",
    "    })\n",
    "\n",
    "# Logistic Regression\n",
    "for C in [0.1, 1, 10]:\n",
    "    clf = LogisticRegression(C=C, max_iter=1000, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_valid)\n",
    "    acc = accuracy_score(y_valid, preds)\n",
    "    results.append({\n",
    "        'model': 'LogisticRegression',\n",
    "        'params': f'C={C}',\n",
    "        'accuracy': acc\n",
    "    })\n",
    "\n",
    "# Print results\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results.sort_values(by='accuracy', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings** The **Decision Tree Model** with max_depth=5 acheieved the highest validation accuracy (0.79). It outperformed other models and hyperparameter configuartions.\n",
    "The **Random Forest Models** also performed well, with the best result from n_estimators=50 (accuracy 0.785), closely followed by n_estimators=100 and n_estimators=10.\n",
    "**Logistic Regression Models**, regardless of the regularization parameter C, had slightly lower accuracy (~0.74), not surpassing the 0.75 threshold.\n",
    "Overall, **tree-based models** (Decision Tree and Random Forest) provided better accuracy than Logistic Regression for this classification task.\n",
    "All models **except** Logisctic Regression surpassed the project's rquired accuarcy threshold of 0.75.\n",
    "In conclusion, the **Decision Tree** with max_depth=5 was the **best performing** model in the study!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.801\n"
     ]
    }
   ],
   "source": [
    "# Load train and test splits\n",
    "X_train = pd.read_csv('X_train.csv')\n",
    "y_train = pd.read_csv('y_train.csv').squeeze()\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "y_test = pd.read_csv('y_test.csv').squeeze()\n",
    "\n",
    "# Train the best model (DecisionTree with max_depth=5)\n",
    "model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test set accuracy: {test_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check Summary**\n",
    "**Accuracy Consistency:** The model's validation (0.79) and test (0.80) accuracies are close, which indicates no major overfitting or underfitting.\n",
    "\n",
    "**Conclusion:**  \n",
    "The Decision Tree model (`max_depth=5`) passes all sanity checks. It generalizes well, uses relevant features, and reliably predicts the classes. No obvious issues are detected in its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "In this project, we set out to build a reliable classifier for predicting user plan choices using their activity data. The dataset was carefully split into training, validation, and test sets to ensure fair model evaluation.\n",
    "\n",
    "After comparing multiple models, Tree-based models (Decision Tree and Random Forest) consistently outperformed Logistic Regression. The best-performing model was a Decision Tree with a maximum depth of 5, achieving a validation accuracy of 0.79.\n",
    "\n",
    "When evaluated on the test set, the Decision Tree model achieved an accuracy of 0.80, confirming its ability to generalize well to new, unseen data. Sanity check shows the model's validation (0.79) and test (0.80) accuracies are close, which indicates no major overfitting or underfitting.\n",
    "\n",
    "Overall, the project successfully developed a robust model that meets the required accuracy threshold. The results demonstrate that tree-based models are effective for this classification task, providing reliable and interpretable predictions that can support business decision-making."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
