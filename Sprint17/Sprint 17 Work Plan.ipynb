{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b7cb50-4006-4cfc-9f6f-cd885332d3c4",
   "metadata": {},
   "source": [
    "# Work Plan- Telecom Churn Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbfc38b-0a77-45ee-a219-d5037c1102ed",
   "metadata": {},
   "source": [
    "Data sources\n",
    "- contract.csv — contract info (customerID, Contract, MonthlyCharges, TotalCharges, PaymentMethod, EndDate, etc.)\n",
    "- personal.csv — personal customer data (customerID, gender, SeniorCitizen, Partner, Dependents, etc.)\n",
    "- internet.csv — internet services (customerID, OnlineSecurity, OnlineBackup, DeviceProtection, StreamingTV, StreamingMovies, InternetService)\n",
    "- phone.csv — phone services (customerID, MultipleLines, PhoneService)\n",
    "- merged_raw_snapshot.csv (merged data)\n",
    "- merged_clean.csv (merged/clean data)\n",
    "- Merge strategy: inner/left join on customerID to create master table (rows = unique customers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f29ccfd-9a61-4008-8f80-3be57870156a",
   "metadata": {},
   "source": [
    "## Notes about the contract database:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73819a3-dfb8-43e2-82c3-fe3492a49494",
   "metadata": {},
   "source": [
    "The goal of the Telecom Churn Project is to develop a model that will be able to forecast if the clients are planning to leave. Interconnect's goal is to learn if their client's are going to churn so they can offer them special deals, in hopes of getting them to stay. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08c614b-867a-4a62-9c5e-e78cdff28298",
   "metadata": {},
   "source": [
    "**What has been done in the Preprocessing stage:**\n",
    "\n",
    "- Normalized column names (stripped whitespace).\n",
    "- Read CSVs safely (low_memory=False) and printed shapes/heads.\n",
    "- Checked for duplicate customerID rows (none present in raw files).\n",
    "- Parsed dates:\n",
    "    - BeginDate → datetime.\n",
    "    - Kept EndDate raw, created EndDate_parsed = parsed date or NaT (preserved raw to avoid leakage).\n",
    "- Computed snapshot-based tenure: tenure_months_snapshot from BeginDate → 2020-02-01.\n",
    "- Coerced numeric columns to numeric:\n",
    "    - MonthlyCharges and TotalCharges → numeric (errors='coerce').\n",
    "- Deterministic imputation for TotalCharges:\n",
    "    - 11 missing originally; filled with MonthlyCharges * tenure_months_snapshot (then fallback to MonthlyCharges and median) → no remaining TotalCharges NA.\n",
    "- Merged the four tables on customerID (left-join on contract), saved merged snapshot CSV.\n",
    "- Checked merge coverage / missingness:\n",
    "    - InternetService missing = 1,526 (21.67%) — likely means \"no internet service\".\n",
    "    - MultipleLines missing = 682 (9.68%) — likely means \"no phone service\".\n",
    "- Converted common Yes/No flags into binary columns (Yes→1, No→0), normalized small categorical columns (strip).\n",
    "- Created a small set of deterministic derived features:\n",
    "    - num_internet_services (sum of internet-related flags)\n",
    "    - has_internet (InternetService != 'No')\n",
    "    - has_phone (from MultipleLines)\n",
    "    - num_services = internet services + phone\n",
    "    - avg_monthly_from_total = TotalCharges / tenure_months_snapshot (fallback to MonthlyCharges)\n",
    "    - payment_auto flag (PaymentMethod contains 'automatic')\n",
    "- Created two explicit label columns (kept both for transparency):\n",
    "    - churn_left = EndDate_parsed.notna() (left before snapshot)\n",
    "    - active_at_snapshot = EndDate_raw == 'No' (active at snapshot) — per Clarification Summary, I believe this is the assignment target by default\n",
    "    - set chosen_target = active_at_snapshot \n",
    "- Saved artifacts:\n",
    "    - data/processed/merged_clean.csv (cleaned table)\n",
    "    - models/preprocessor_template.joblib (an unfitted ColumnTransformer template)\n",
    "    - saved a merged_raw_snapshot for traceability\n",
    "\n",
    "**Tasks to be done in the EDA stage:**\n",
    "- Visualizations\n",
    "- Checking distributions, skewness, seasonality, and outliers in detail.\n",
    "- Identifying which engineered features help and which are redundant\n",
    "- Deciding on encoding strategies after seeing cardinalities and rare categories (target encoding vs one-hot).\n",
    "- Choosing class imbalance technique after seeing model baselines.\n",
    "\n",
    "**Tasks in Feature Engineering stage:**\n",
    "- Finalize service flags, tenure bins, payment/contract one-hots, and missingness indicators.\n",
    "- Add ratios and avg_monthly_from_total variants, run quick RF probe and measure AUC gain.\n",
    "- Test a small set of interactions and categorical groupings, then run feature selection/SHAP to prune.\n",
    "- If dimensionality grows, apply reduction or target encoding carefully and re-evaluate.\n",
    "\n",
    "Use stratified CV optimizing AUC-ROC: compare baseline model → add feature blocks (e.g., contract/payment, service counts, interactions) and measure delta AUC; use permutation importance / SHAP and simple ablation (remove features/groups) to validate usefulness and avoid overfitting. Keep features that consistently improve mean CV AUC and are stable across folds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e953adf-2ee5-46b4-9304-6678e36495d2",
   "metadata": {},
   "source": [
    "## Proposed Work Plan:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52068b26-ac80-4013-a7b1-d263b44d2b57",
   "metadata": {},
   "source": [
    "1. Download the data\n",
    "2. Explore the data to determine how to treat it in the preprocessing stage\n",
    "3. Perform preprocessing on the data\n",
    "4. Perform Exploratory Data Analysis to explore the data in depth\n",
    "5. Feature Engineering (Develop a model and prepare a report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2252a98d-5adb-43e9-bd40-59a107849bea",
   "metadata": {},
   "source": [
    "## Clarifying Questions:\n",
    "1. First and foremost, I feel like I'm making this way more complicated and difficult than it needs to be. Am I getting in my head and over-complicating this and doing too much? Because before I turned this first part in I re-did the preprocessing code three times thinking I wasn't doing enough, which also may have caused problems.\n",
    "2. Should missing InternetService/MultipleLines be treated as explicit 'No service' or kept as NaN (with a missingness indicator)?\n",
    "3. Is there any preference for interpretable models (logistic regression / shallow trees) vs. black‑box ensembles? Do you expect a SHAP analysis or feature importance for the final submission?\n",
    "4. The Clarification Summary says Target = EndDate == 'No', should I treat EndDate == 'No' (active) as the positive class, or do you want to model churn (EndDate != 'No') as positive?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
